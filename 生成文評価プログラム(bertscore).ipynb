{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honomax/text-kantei/blob/main/%E7%94%9F%E6%88%90%E6%96%87%E8%A9%95%E4%BE%A1%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0(bertscore).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Driveのマウント"
      ],
      "metadata": {
        "id": "jUXdBAOjm42b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EmZU-vhum22f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pipインストール"
      ],
      "metadata": {
        "id": "3R72xt7cnMNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-score"
      ],
      "metadata": {
        "id": "Xr4Bl7-1mecA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ライブラリのインポート\n"
      ],
      "metadata": {
        "id": "RovS0YOFpcB4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLshKbXRCMPY",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from bert_score import score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ファイルの読み込み"
      ],
      "metadata": {
        "id": "OQ3ZKq99WtJv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60a4fe09"
      },
      "source": [
        "base_dir = \"/content/drive/MyDrive/text-kantei\"\n",
        "file_name = \"data/text_list.csv\"\n",
        "file_path = os.path.join(base_dir, file_name)\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gpt_answerとbot_answerの計算"
      ],
      "metadata": {
        "id": "cX4PwQfqtX0Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71c0a47f"
      },
      "source": [
        "references = df['reference'].fillna('').tolist()\n",
        "candidates_gpt = df['gpt_answer'].fillna('').tolist()\n",
        "candidates_bot = df['bot_answer'].fillna('').tolist()\n",
        "\n",
        "def calculate_bertscore(candidates, references, lang=\"ja\", model_type=\"bert-base-multilingual-cased\"):\n",
        "    P, R, F1 = score(candidates, references, lang=lang, model_type=model_type)\n",
        "    return P.numpy(), R.numpy(), F1.numpy()\n",
        "\n",
        "# BERTScoreの計算(gpt_answer)\n",
        "P_gpt, R_gpt, F1_gpt = calculate_bertscore(candidates_gpt, references)\n",
        "df['bertscore_gpt_precision'] = P_gpt\n",
        "df['bertscore_gpt_recall'] = R_gpt\n",
        "df['bertscore_gpt_f1'] = F1_gpt\n",
        "\n",
        "# BERTScoreの計算(bot_answer)\n",
        "P_bot, R_bot, F1_bot = calculate_bertscore(candidates_bot, references)\n",
        "df['bertscore_bot_precision'] = P_bot\n",
        "df['bertscore_bot_recall'] = R_bot\n",
        "df['bertscore_bot_f1'] = F1_bot\n",
        "\n",
        "# 平均値の計算\n",
        "avg_bertscore_gpt_precision = df['bertscore_gpt_precision'].mean()\n",
        "avg_bertscore_gpt_recall = df['bertscore_gpt_recall'].mean()\n",
        "avg_bertscore_gpt_f1 = df['bertscore_gpt_f1'].mean()\n",
        "\n",
        "avg_bertscore_bot_precision = df['bertscore_bot_precision'].mean()\n",
        "avg_bertscore_bot_recall = df['bertscore_bot_recall'].mean()\n",
        "avg_bertscore_bot_f1 = df['bertscore_bot_f1'].mean()\n",
        "\n",
        "# 結果の表示\n",
        "print(\"BERTScore GPT 平均値:\")\n",
        "print(f\"  Precision: {avg_bertscore_gpt_precision:.4f}\")\n",
        "print(f\"  Recall: {avg_bertscore_gpt_recall:.4f}\")\n",
        "print(f\"  F1-score: {avg_bertscore_gpt_f1:.4f}\")\n",
        "\n",
        "print(\"\\nBERTScore BOT 平均値:\")\n",
        "print(f\"  Precision: {avg_bertscore_bot_precision:.4f}\")\n",
        "print(f\"  Recall: {avg_bertscore_bot_recall:.4f}\")\n",
        "print(f\"  F1-score: {avg_bertscore_bot_f1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.head())"
      ],
      "metadata": {
        "id": "3xFQaF5QGXt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERTスコアの計算"
      ],
      "metadata": {
        "id": "0A6sK65Dietd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4569ecf"
      },
      "source": [
        "# 結果の保存\n",
        "output_path = os.path.join(base_dir, \"output.csv\")\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\nBERTScoreの計算結果を以下のファイルに保存しました: {output_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}